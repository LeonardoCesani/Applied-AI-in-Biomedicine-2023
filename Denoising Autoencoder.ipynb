{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "machine_shape": "hm",
   "collapsed_sections": [
    "60arFp7xo6kE",
    "YzKdlUraoALs",
    "rpfP8g4B-C5k",
    "hc93Q6JgCktY",
    "-HXCf7PJQWBA",
    "FDCGgvMe_oU6",
    "0hsWZAqpNGrU",
    "8n7ynOqUnCLq"
   ],
   "gpuType": "T4",
   "authorship_tag": "ABX9TyOnNdOtwErmUUYZS0KN3qYP"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Denoising Autoencoder\n",
    "In this script I try to implement a denoising autoencoder for PPG signals.\n",
    "Since the data provided for the Applied AI in Biomedicine project course comprise artifacs, I will use an external dataset of PPG signals to train the model. A Denoising Autoencoder is an architecture proposed by Vincent et al. in 2008 aiming to cancel the noise on images, allowing to produce a clean image (https://www.cs.toronto.edu/~larocheh/publications/icml-2008-denoising-autoencoders.pdf). I will try to implement a version of the denoising autoencoder for signals using 1D convolutions over the input vector.\n",
    "Due to the non-effectiveness of this method in our context, a plain autoencoder will be trained in order to cope with the filtering of the dataset."
   ],
   "metadata": {
    "id": "SybxBwYom3xY"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import Libraries\n"
   ],
   "metadata": {
    "id": "YzKdlUraoALs"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# General purpose libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import os\n",
    "\n",
    "# Plotting libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# PPG library\n",
    "!pip install neurokit2\n",
    "import neurokit2 as nk\n",
    "\n",
    "# Optimization library\n",
    "!pip install optuna\n",
    "import optuna\n",
    "\n",
    "# Deep learning libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras as tfk\n",
    "from keras import layers as tfkl\n",
    "from keras import backend as K"
   ],
   "metadata": {
    "id": "Xt4Zidl-n_7Z"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Denoising Autoencoder Class\n",
    "The following class provides all the methods to deal with the creation and training of a denoising autoencoder."
   ],
   "metadata": {
    "id": "rpfP8g4B-C5k"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Define the class for the autoencoder\n",
    "\n",
    "class DenoisingAutoencoder:\n",
    "    \"\"\"\n",
    "    @description: built a Denoising Autoencoder using TensorFlow and Keras layers.\n",
    "\n",
    "    @params:\n",
    "    - lenght (int): length of the input vector\n",
    "    - filters (tuple of int): number of filters for the specified convolutional layers of the encoder\n",
    "    - latentDim (int): size of the latent dimension of the autoencoder\n",
    "\n",
    "    @return: none\n",
    "    \"\"\"\n",
    "    def __init__(self,length, filters=(32, 64), latentDim=16, lr = 0.001):\n",
    "      self.length = length\n",
    "      self.filters = filters\n",
    "      self.latentDim = latentDim\n",
    "      self.lr = lr\n",
    "\n",
    "    def build(self):\n",
    "        \"\"\"\n",
    "        @description: build the autoencoder model. (1) builds the encoder,\n",
    "                    (2) builts the decoder, (3) builds the model, (4) compile the model\n",
    "\n",
    "        @params: the object itself\n",
    "\n",
    "        @return: none\n",
    "        \"\"\"\n",
    "\n",
    "        encoder_inputs = tfkl.Input(shape=(self.length, 1))\n",
    "\n",
    "        # 1. Create the encoder\n",
    "        encoder = encoder_inputs\n",
    "\n",
    "        if type(self.filters) != int:\n",
    "          for f in self.filters:\n",
    "            # 1.1. Convolutional layer\n",
    "            encoder = tfkl.Conv1D(filters = f, kernel_size = 3, padding = 'same',\n",
    "                                  activation = 'relu', kernel_initializer=tfk.initializers.HeNormal(seed=None))(encoder)\n",
    "        else:\n",
    "            encoder = tfkl.Conv1D(filters = self.length, kernel_size = 3,\n",
    "                                  padding = 'same', activation = 'relu',\n",
    "                                  kernel_initializer=tfk.initializers.HeNormal(seed=None))(encoder)\n",
    "        # 2.1. Batch Normalization\n",
    "        encoder = tfkl.BatchNormalization()(encoder)\n",
    "\n",
    "        # Flatten the output of the last conv1d layer\n",
    "        flattened = tfkl.Flatten()(encoder)\n",
    "\n",
    "        # Create the latent space\n",
    "        latent_space = tfkl.Dense(units = self.latentDim)(flattened)\n",
    "\n",
    "        # 2. Create the decoder.\n",
    "        # The decoder will accept as input the output of the encoder.\n",
    "        if type(self.filters) != int:\n",
    "          decoded = tfkl.Dense(self.filters[-1]*(self.length), activation = 'relu')(latent_space)\n",
    "          # Reshape the decoder\n",
    "          decoded = tfkl.Reshape((self.length, self.filters[-1]))(decoded)\n",
    "        else:\n",
    "          decoded = tfkl.Dense(self.filters*(self.length), activation = 'relu')(latent_space)\n",
    "          # Reshape the decoder\n",
    "          decoded = tfkl.Reshape((self.length, self.filters))(decoded)\n",
    "\n",
    "        # Define the decoder layers\n",
    "        if type(self.filters) != int:\n",
    "          for f in reversed(self.filters[:-1]):\n",
    "              decoded = tfkl.Conv1DTranspose(filters = f, kernel_size = 3, activation='relu', padding = 'same')(decoded)\n",
    "        else:\n",
    "              decoded = tfkl.Conv1DTranspose(filters = self.filters, kernel_size = 3, activation='relu', padding = 'same')(decoded)\n",
    "        # Define the decoder's output\n",
    "        decoder_output = tfkl.Conv1DTranspose(filters = 1, kernel_size = 3,\n",
    "                                        activation='linear', padding = 'same')(decoded)\n",
    "\n",
    "        # Build the model\n",
    "        model = tfk.models.Model(encoder_inputs, decoder_output, name='denoising_autoencoder')\n",
    "\n",
    "        # Define the optimizator\n",
    "        opt = tfk.optimizers.Adam(learning_rate = self.lr)\n",
    "\n",
    "        # Compile the model\n",
    "        model.compile(loss='mse', optimizer = opt, )\n",
    "\n",
    "        self.denoisingAutoencoder = model\n",
    "\n",
    "        # self.denoisingAutoencoder.summary()\n",
    "\n",
    "\n",
    "    def train(self, X_train, X_train_noisy, X_val, X_val_noisy, callbacks,\n",
    "                epochs = 20, batch_size = 64):\n",
    "        \"\"\"\n",
    "        @description: train a denoising autoencoder\n",
    "\n",
    "        @params:\n",
    "        - X_train (vector of int): training signals\n",
    "        - X_train_noisy (vector of int): noisy training signals\n",
    "        - X_val (vector of int): validation signals\n",
    "        - X_val_noisy (vector of int): noisy validation signals\n",
    "        - callbacks (vector of tensorflow's callbacks): the callbacks to be included in the training\n",
    "        - epochs (int): number of (maximum) training epochs\n",
    "        - batch_size: (int) batch_size dimension\n",
    "\n",
    "        @return: none\n",
    "        \"\"\"\n",
    "        if X_val_noisy is not None and X_val is not None:\n",
    "          # Train monitoring validation loss\n",
    "          self.history = self.denoisingAutoencoder.fit(\n",
    "              x=X_train_noisy,\n",
    "              y=X_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(X_val_noisy, X_val),\n",
    "              callbacks=callbacks\n",
    "          ).history\n",
    "\n",
    "          # Plot the training history\n",
    "          self._plotHistory(epochs)\n",
    "        else:\n",
    "          # Train without monitoring validation loss\n",
    "          self.history = self.denoisingAutoencoder.fit(\n",
    "              x=X_train_noisy,\n",
    "              y=X_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs\n",
    "          ).history\n",
    "\n",
    "\n",
    "\n",
    "        # Save the model\n",
    "        self.denoisingAutoencoder.save(\"DenoisingAutoencoder\")\n",
    "\n",
    "        return self.denoisingAutoencoder\n",
    "\n",
    "    def _plotHistory(self, epochs):\n",
    "        \"\"\"\n",
    "        @description: plot the history of the training of a denoising autoencoder\n",
    "\n",
    "        @params:\n",
    "        - epochs (int): number of epochs\n",
    "\n",
    "        @return: none\n",
    "        \"\"\"\n",
    "\n",
    "        history = self.history\n",
    "\n",
    "        best_epoch = np.argmin(history['val_loss'])\n",
    "        plt.figure(figsize=(17,4))\n",
    "        plt.plot(history['loss'][1:], label='Training loss', alpha=.8, color='#ff7f0e')\n",
    "        plt.plot(history['val_loss'][1:], label='Validation loss', alpha=.9, color='#5a9aa5')\n",
    "        plt.axvline(x=best_epoch, label='Best epoch', alpha=.3, ls='--', color='#5a9aa5')\n",
    "        plt.title('Categorical Crossentropy')\n",
    "        plt.legend()\n",
    "        plt.grid(alpha=.3)\n",
    "        plt.show()\n",
    "\n",
    "    def setLearningRate(self, lr):\n",
    "        self.lr = lr\n"
   ],
   "metadata": {
    "id": "kuITMJyEm3dR"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Generation"
   ],
   "metadata": {
    "id": "hc93Q6JgCktY"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Generate 100 PPG signals\n",
    "signals = []\n",
    "for i in range(200):\n",
    "  bpm = np.random.randint(65, 80)\n",
    "  fs = 250\n",
    "  ppg = nk.ppg_simulate(duration=200, sampling_rate=fs, heart_rate=bpm,\n",
    "                        ibi_randomness = 0.01, frequency_modulation = 0.1,\n",
    "                        drift = 0.1, motion_amplitude = 0.1,)\n",
    "  signals.append({'ppg': ppg, 'bpm': bpm})\n"
   ],
   "metadata": {
    "id": "1FoL8tlN_aZX"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Plot one signal\n",
    "idx = 18\n",
    "sample_frequency = 128 # Hz\n",
    "time_values = np.arange(len(signals[len(signals) - 1]['ppg'])) / sample_frequency\n",
    "# Plot the signal\n",
    "plt.plot(time_values, signals[idx]['ppg'])\n",
    "plt.xlabel('Time (seconds)')\n",
    "plt.ylabel('Signal Amplitude')\n",
    "plt.title('Signal Plot')\n",
    "plt.grid(True)\n",
    "plt.xlim(0, 25)\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "OYwJ8Zi1Gyr5"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Generate the dataset to be feed to the autoencoder\n",
    "\n",
    "# Define window and stride\n",
    "window = 200\n",
    "stride = 50\n",
    "\n",
    "dataset = []\n",
    "\n",
    "for ppg in signals:\n",
    "    # Take only meaningful features\n",
    "    temp = ppg['ppg']\n",
    "\n",
    "    # Standardize the signal\n",
    "    mean = np.mean(temp)\n",
    "    std_dev = np.std(temp)\n",
    "    standardized_temp = (temp - mean) / std_dev\n",
    "\n",
    "    # Compute padding length\n",
    "    padding_len = window - len(temp)%window\n",
    "    # Create padding and concatenate it\n",
    "    padding = np.zeros(padding_len, dtype='float32')\n",
    "    temp = np.concatenate((temp, padding))\n",
    "    # Build features windows with their corresponging labels\n",
    "    idx = 0\n",
    "    while idx+window <= len(temp):\n",
    "        dataset.append(temp[idx:idx+window])\n",
    "        idx += stride\n",
    "dataset = np.array(dataset) # composed of chunks and labels\n",
    "\n",
    "dataset.shape\n"
   ],
   "metadata": {
    "id": "46N4jYvOHFJu"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Perform the train-validation-test split\n",
    "X_train = dataset[:80000]\n",
    "X_val = dataset[80000:95000]\n",
    "X_test = dataset[95000:len(dataset)]\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)\n"
   ],
   "metadata": {
    "id": "GA-y4XdoMK4L"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Generate the noisy samples\n",
    "trainNoise = np.random.normal(loc=np.mean(X_train), scale= 0.1, size=X_train.shape)\n",
    "valNoise = np.random.normal(loc=np.mean(X_val), scale= 0.1, size=X_val.shape)\n",
    "testNoise = np.random.normal(loc=np.mean(X_test), scale= 0.1, size=X_test.shape)\n",
    "\n",
    "X_train_noisy = np.clip(X_train + trainNoise, np.min(X_train + trainNoise), np.max(X_train + trainNoise))\n",
    "X_val_noisy = np.clip(X_val + valNoise, np.min(X_val + valNoise), np.max(X_val + valNoise))\n",
    "X_test_noisy = np.clip(X_test + testNoise, np.min(X_test + testNoise), np.max(X_test + testNoise))\n",
    "\n",
    "# Set some noisy samples identical to the plain samples, in such a way that the model\n",
    "# does not learn only to modify the signal\n",
    "i = 0\n",
    "rnd_train = []\n",
    "while(i < int(X_train_noisy.shape[0]* 0.4)):\n",
    "  rnd = np.random.randint(0,X_train_noisy.shape[0])\n",
    "  rnd_train.append(rnd)\n",
    "  X_train_noisy[rnd] = X_train[rnd]\n",
    "  i += 1\n",
    "\n",
    "i = 0\n",
    "rnd_val = []\n",
    "while(i < int(X_val_noisy.shape[0]* 0.4)):\n",
    "  rnd = np.random.randint(0,X_val_noisy.shape[0])\n",
    "  rnd_val.append(rnd)\n",
    "  X_val_noisy[rnd] = X_val[rnd]\n",
    "  i += 1\n",
    "\n",
    "i = 0\n",
    "rnd_test = []\n",
    "while(i < int(X_test_noisy.shape[0]* 0.4)):\n",
    "  rnd = np.random.randint(0,X_test_noisy.shape[0])\n",
    "  rnd_test.append(rnd)\n",
    "  X_test_noisy[rnd] = X_test[rnd]\n",
    "  i += 1\n",
    "\n",
    "# Add some artifacts to some of the samples (excluded the previous ones)\n",
    "i = 0\n",
    "while(i < int(X_train_noisy.shape[0]* 0.3)):\n",
    "  rnd = np.random.randint(0,X_train_noisy.shape[0])\n",
    "  while rnd in rnd_train:\n",
    "    rnd = np.random.randint(0,X_train_noisy.shape[0])\n",
    "\n",
    "  num_spikes = np.random.randint(100, 200)\n",
    "  spike_indices = np.random.randint(0, len(X_train_noisy[rnd]), num_spikes)\n",
    "  spike_magnitudes = np.random.randint(-50, 50, num_spikes)\n",
    "  for idx, mag in zip(spike_indices, spike_magnitudes):\n",
    "    X_train_noisy[rnd][idx] += mag\n",
    "  i += 1\n",
    "\n",
    "i = 0\n",
    "while(i < int(X_val_noisy.shape[0]* 0.3)):\n",
    "  rnd = np.random.randint(0,X_val_noisy.shape[0])\n",
    "  while rnd in rnd_val:\n",
    "    rnd = np.random.randint(0,X_val_noisy.shape[0])\n",
    "\n",
    "  num_spikes = np.random.randint(100, 200)\n",
    "  spike_indices = np.random.randint(0, len(X_val_noisy[rnd]), num_spikes)\n",
    "  spike_magnitudes = np.random.randint(-50, 50, num_spikes)\n",
    "  for idx, mag in zip(spike_indices, spike_magnitudes):\n",
    "    X_val_noisy[rnd][idx] += mag\n",
    "  i += 1\n",
    "\n",
    "\n",
    "i = 0\n",
    "while(i < int(X_test_noisy.shape[0]* 0.3)):\n",
    "  rnd = np.random.randint(0,X_test_noisy.shape[0])\n",
    "  while rnd in rnd_test:\n",
    "    rnd = np.random.randint(0,X_test_noisy.shape[0])\n",
    "\n",
    "  num_spikes = np.random.randint(100, 200)\n",
    "  spike_indices = np.random.randint(0, len(X_test_noisy[rnd]), num_spikes)\n",
    "  spike_magnitudes = np.random.randint(-50, 50, num_spikes)\n",
    "  for idx, mag in zip(spike_indices, spike_magnitudes):\n",
    "    X_test_noisy[rnd][idx] += mag\n",
    "  i += 1\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "id": "xWOGi-bUM7TM"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "idx = rnd\n",
    "# Plot one signal\n",
    "sample_frequency = 128 # Hz\n",
    "time_values = np.arange(len(X_test[idx]))\n",
    "# Plot the signal\n",
    "plt.plot(time_values, X_test[idx])\n",
    "plt.xlabel('Time (seconds)')\n",
    "plt.ylabel('Signal Amplitude')\n",
    "plt.title('Signal Plot')\n",
    "plt.grid(True)\n",
    "plt.xlim(30, len(X_test[idx]))\n",
    "plt.show()\n",
    "\n",
    "# Plot one signal\n",
    "sample_frequency = 128 # Hz\n",
    "time_values = np.arange(len(X_test_noisy[idx]))\n",
    "# Plot the signal\n",
    "plt.plot(time_values, X_test_noisy[idx])\n",
    "plt.xlabel('Time (seconds)')\n",
    "plt.ylabel('Signal Amplitude')\n",
    "plt.title('Signal Plot')\n",
    "plt.grid(True)\n",
    "plt.xlim(30, len(X_test_noisy[idx]))\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "Tq32xKM3OBcc"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Set the correct shapes\n",
    "X_train = np.expand_dims(X_train, axis = -1)\n",
    "X_val = np.expand_dims(X_val, axis = -1)\n",
    "X_test = np.expand_dims(X_test, axis = -1)\n",
    "\n",
    "\n",
    "X_train_noisy = np.expand_dims(X_train_noisy, axis = -1)\n",
    "X_val_noisy = np.expand_dims(X_val_noisy, axis = -1)\n",
    "X_test_noisy = np.expand_dims(X_test_noisy, axis = -1)\n",
    "\n",
    "print(\"Train shapes: \", X_train.shape, X_train_noisy.shape)\n",
    "print(\"Validation shapes: \", X_val.shape, X_val_noisy.shape)\n",
    "print(\"Test shapes: \", X_test.shape, X_test_noisy.shape)"
   ],
   "metadata": {
    "id": "AlBTewSbYs-9"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "X_train = np.expand_dims(X_train, axis = -1)\n",
    "X_val = np.expand_dims(X_val, axis = -1)\n",
    "X_test = np.expand_dims(X_test, axis = -1)\n",
    "\n",
    "print(\"Train shapes: \", X_train.shape)\n",
    "print(\"Validation shapes: \", X_val.shape)\n",
    "print(\"Test shapes: \", X_test.shape)"
   ],
   "metadata": {
    "id": "oxt8I6MO5Lg9"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train the Model"
   ],
   "metadata": {
    "id": "-HXCf7PJQWBA"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Define a denoising autoencoder instance\n",
    "input_shape = X_train.shape\n",
    "denoising_autoencoder = DenoisingAutoencoder(length = input_shape[1], filters=(8, 16), lr = 1e-3)\n",
    "\n",
    "# Build the model\n",
    "denoising_autoencoder.build()"
   ],
   "metadata": {
    "id": "7SyOc5BaQYpg"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "callbacks = [\n",
    "        tfk.callbacks.EarlyStopping(monitor='val_loss', mode='max', patience=15, restore_best_weights=True),\n",
    "        tfk.callbacks.ReduceLROnPlateau(monitor='val_loss', mode='max', patience=5, factor=0.5)\n",
    "]\n",
    "# Train the model\n",
    "denoising_autoencoder.train(X_train = X_train, X_train_noisy = X_train_noisy, X_val = X_val, X_val_noisy=X_val_noisy, callbacks=callbacks)\n"
   ],
   "metadata": {
    "id": "2g71i81fRDtg"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "del denoising_autoencoder"
   ],
   "metadata": {
    "id": "CA9tNxorUgVB"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Hyperparameter tuning of the Denoising Autoencoder"
   ],
   "metadata": {
    "id": "FDCGgvMe_oU6"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "callbacks = [\n",
    "             tfk.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
    "             tfk.callbacks.ReduceLROnPlateau(monitor='val_loss', patience=5, factor=0.5)\n",
    "            ]\n",
    "\n",
    "# Objective function\n",
    "def objective_function(optuna_trial):\n",
    "\n",
    "    denoisingAutoencoder = DenoisingAutoencoder(\n",
    "                                                length = X_train.shape[1],\n",
    "                                                lr = 0.01,\n",
    "                                                filters=optuna_trial.suggest_categorical('filters', [(256, 128, 64, 32), (128, 64, 32), (64, 32), (64, 32, 16), (32, 18)]),\n",
    "                                                latentDim=optuna_trial.suggest_categorical('latentDim', [128, 64, 32, 16, 8])\n",
    "                                                )\n",
    "    denoisingAutoencoder.build()\n",
    "\n",
    "    # Train the model\n",
    "    model = denoisingAutoencoder.train(X_train = X_train,\n",
    "                                       X_train_noisy = X_train,\n",
    "                                       X_val = X_val,\n",
    "                                       X_val_noisy = X_val,\n",
    "                                       callbacks = callbacks,\n",
    "                                       batch_size=optuna_trial.suggest_categorical(\"batch_size\", [256, 128, 64, 32, 16])\n",
    "                                       )\n",
    "\n",
    "    predictions = model.predict(X_val)\n",
    "    mse = np.mean(np.square(predictions - X_val))\n",
    "\n",
    "    # delete the model and the DenoisingAutoencoder object\n",
    "    del model\n",
    "    del denoisingAutoencoder\n",
    "\n",
    "    return mse\n"
   ],
   "metadata": {
    "id": "eHZ-GwJ8_1k3"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "# Define the optimization study\n",
    "optuna_study = optuna.create_study(direction=\"minimize\")\n",
    "\n",
    "optuna_study.optimize(objective_function, n_trials = 20)"
   ],
   "metadata": {
    "id": "XNBvvy0sA9Sg"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "optuna_study.best_trial.params"
   ],
   "metadata": {
    "id": "pbQPAt1mFKg_"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Finetune the Model with the Best Parameters"
   ],
   "metadata": {
    "id": "0hsWZAqpNGrU"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# {'filters': (64, 32), 'latentDim': 64, 'batch_size': 128}\n",
    "input_shape = X_train.shape\n",
    "callbacks = [\n",
    "             tfk.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
    "             tfk.callbacks.ReduceLROnPlateau(monitor='val_loss', patience=5, factor=0.5)\n",
    "            ]\n",
    "\n",
    "# Define a denoising autoencoder instance\n",
    "denoising_autoencoder = DenoisingAutoencoder(length = input_shape[1], lr = 0.002581221789660623, filters = (64, 32), latentDim = 64)\n",
    "denoising_autoencoder.build()\n",
    "denoising_autoencoder.train(X_train = X_train, X_train_noisy = X_train, X_val = X_val, X_val_noisy=X_val, callbacks=callbacks, batch_size=128, epochs = 50)"
   ],
   "metadata": {
    "id": "WigKg75GNGIS"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Finetune the model with a low learning rate\n",
    "denoising_autoencoder.setLearningRate(lr=1e-5)\n",
    "denoising_autoencoder.train(X_train = X_train, X_train_noisy = X_train, X_val = X_val, X_val_noisy=X_val, callbacks=callbacks, batch_size=16, epochs = 25)"
   ],
   "metadata": {
    "id": "1jYEcVpNNrHz"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Retrain the model on the whole dataset (with a small learning rate)\n",
    "denoising_autoencoder.setLearningRate(lr=1e-5)\n",
    "denoising_autoencoder.train(X_train = np.concatenate((X_train, X_val), axis=0),\n",
    "                            X_train_noisy = np.concatenate((X_train, X_val), axis=0),\n",
    "                            X_val = None, X_val_noisy=None, callbacks=None,\n",
    "                            batch_size=128, epochs = 15)"
   ],
   "metadata": {
    "id": "PH3X64HmK3u8"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "del denoising_autoencoder"
   ],
   "metadata": {
    "id": "ZPlb9956Mrxf"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test the Denoising Autoencoder"
   ],
   "metadata": {
    "id": "8n7ynOqUnCLq"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Load the model\n",
    "model = tfk.models.load_model('DenoisingAutoencoder')"
   ],
   "metadata": {
    "id": "NpZR18lGnB8_"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Remove the noise from the test set\n",
    "denoised_data = model.predict(X_test)"
   ],
   "metadata": {
    "id": "lVHBxQBXa5-J"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Define the sampling frequency and time values based on the length of the signal\n",
    "sample_frequency = 128  # Hz\n",
    "time_values = np.arange(len(X_test[1])) / sample_frequency\n",
    "\n",
    "# Rest of the code remains the same for plotting...\n",
    "\n",
    "# Create a single plot with subplots for each signal\n",
    "fig, axs = plt.subplots(2, 1, figsize=(8, 8))\n",
    "index = 4\n",
    "# Real Signal\n",
    "axs[0].plot(time_values, X_test[index])\n",
    "axs[0].set_xlabel('Time (seconds)')\n",
    "axs[0].set_ylabel('Signal Amplitude')\n",
    "axs[0].set_title('Real Signal')\n",
    "axs[0].grid(True)\n",
    "axs[0].set_xlim(30 / sample_frequency, len(X_test[index]) / sample_frequency)\n",
    "\n",
    "# Noisy Signal\n",
    "\"\"\"\n",
    "axs[1].plot(time_values, X_test_noisy[index])\n",
    "axs[1].set_xlabel('Time (seconds)')\n",
    "axs[1].set_ylabel('Signal Amplitude')\n",
    "axs[1].set_title('Noisy Signal')\n",
    "axs[1].grid(True)\n",
    "axs[1].set_xlim(30 / sample_frequency, len(X_test_noisy[index]) / sample_frequency)\n",
    "\"\"\"\n",
    "# Denoised Signal\n",
    "axs[1].plot(time_values, denoised_data[index])\n",
    "axs[1].set_xlabel('Time (seconds)')\n",
    "axs[1].set_ylabel('Signal Amplitude')\n",
    "axs[1].set_title('Denoised Signal')\n",
    "axs[1].grid(True)\n",
    "axs[1].set_xlim(30 / sample_frequency, len(denoised_data[index]) / sample_frequency)\n",
    "\n",
    "# Adjust layout and save the whole figure as an image\n",
    "plt.tight_layout()\n",
    "# plt.savefig('combined_signals.png')  # Save as an image file\n",
    "plt.show()\n"
   ],
   "metadata": {
    "id": "665s8XaZoCP6"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "gGP1mhEWoGqG"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
